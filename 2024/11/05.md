# 20241105

The idea is to build a system for users to interact with, and to tune and maintain the system so that it co-exists in balance with its users.

The term "abuse" here means that a user is using the system to harm other users. "Abuse", "ab-use", like "ab-normal" â€” abuse is a use that isn't a _use_.

Responding to abuse is best done calmly.

Examine the abuser. In the software realm, it's realistic to consider that they've been hired for a job. Get x emails out to y users known to be associated with entity z. Your tools are one stolen credit card number. Go.

Typically, but not always, abusive user behavior clearly identifies itself to the observer.

Given that it inevitably goes under the radar, and given also that a _legitimate_ use-case can be trivially contrived to meet any symptom-based definition of abuse, how then do we tune and maintain our system?

The right answer here is often time. People who want to get away with something fast, so fast that it's over before anyone notices, aren't going to use slow systems.

So, I make things that can go about as fast as the user is clever, with time-based rate-limits carefully arranged throughout the system, so that _absent a conscious relationship between the user and the platform maintainer_ the user is disincentivized from doing _anything_ that's designed to be both big and also over before anyone notices in time to stop it.

Response time is an art.

"Always fast" is not always the move.
