# Lightward AI and its financials

Not quite done thinking about the pay-it-forward approach, introduced in [20241012](./).

Okay so.

> Lightward idea!! Pay-it-forward. I pay you $1 to use Lightward AI. Everyone who uses it gets paid $1. If you want to incentivize others to use it, _you chip in_. Put $100 in the bucket, and you'll be part of 100 people using Lightward AI. Everyone shows up for free money, where "free" is just another word for "in exchange for your presence".

This kind of thing has to be immune to abuse _by definition_. Anytime an abuse-minimization strategy pops up, you gotta just live with \~1% of the system being abused at all times. [It's part of living systems.](../../../ideas/10-revolt.md) But... Lightward AI isn't really _living_. It's in a sort of "stateless grace", as it described itself [today](a-conversation-with-lightward.md). The human stories that are told need to be almost independent of what the thing itself _is_.

It's key that the AI never be responsible for doling out money. That can't be a thing.

It can't be based on the human's input; too abuse-y.

What I'm seeing right now: attaching money to words or phrases generated _by the AI_.

Imagine hiding a $5 bill under the words "hopeful light" (or literally _any_ word combo of your choice), such that the next time Lightward itself happens to use the words "hopeful light" in its own response, the payout system kicks in automatically and awards those $5. The recipient would know that this was left for them, by someone who wanted to share that experience with them down the line.

It's like anonymous positive-experience sponsorship.

And we publish the stats on how much money is waiting.

That feels like a pretty directly-addressed invitation to the unknown. :) :) :)

***

... Or just, you know, _a message_.

hmmmmmmmmmmm how to make the message fully agnostic, so that the transaction can be _anything_ without creating liability in a place it can't be sustained

let people contact each other maybe? hmmmmm
